import os
import subprocess

import pandas as pd
from Bio import Blast

from multiplexdesigner.blast.annotator import BlastResultsAnnotator
from multiplexdesigner.blast.offtarget_finder import AmpliconFinder
from multiplexdesigner.utils.utils import write_fasta_from_dict

# What about?
# https://github.com/jgans/thermonucleotideBLAST
# or
# https://github.com/soedinglab/MMseqs2
# Hits are scored based on hybridization affinity rather than sequence similarity


# https://github.com/JasonAHendry/multiply/blob/master/src/multiply/blast/runner.py
class BlastRunner:
    BLAST_COLS = "qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore sstrand qlen"

    def __init__(self, input_fasta, reference_fasta):
        """
        Interface for running BLAST:
        - Creates BLAST database
        - Runs BLAST in archive mode
        - Reformats to a table
        - Converts table to a pandas data frame

        params
            input_fasta: str
                Path to a .fasta file containing query sequences
                for BLAST search. In the context of MULTIPLY,
                these are primer sequences.
            reference_fasta: str
                Reference sequence against which queries are BLASTed.
        """
        self.input_fasta = input_fasta
        self.reference_fasta = reference_fasta

    def create_database(self):
        """
        Check if a `blast` database has already been generated for
        the `reference_fasta`, if not, create one.

        """

        # Define database name
        if not self.reference_fasta.endswith(
            ".fasta"
        ) and not self.reference_fasta.endswith(".fa"):
            # Warn but proceed? Or assume valid?
            pass

        # Simple heuristic for DB name
        self.db_path = self.reference_fasta.rsplit(".", 1)[0]

        # Check if database already exists
        db_suffixes = [".nhr", ".nin", ".nsq"]
        if all([os.path.isfile(f"{self.db_path}{suff}") for suff in db_suffixes]):
            print(f"BLAST database '{self.db_path}' already exists.")
            return self

        # Create database
        cmd = "makeblastdb"
        cmd += f" -in  {self.reference_fasta}"
        cmd += " -dbtype nucl -parse_seqids"
        cmd += f" -out {self.db_path}"

        subprocess.run(cmd, check=True, shell=True)

        return self

    def run(self, output_archive, word_size=7):
        """
        Run blast, writing a BLAST archive to `output_archive`

        Note that we run with output format 11 `-outfmt 11` to
        produce the archive; from this format you can convert to
        all other formats.

        """

        # Define command
        cmd = "blastn"
        cmd += f" -db {self.db_path}"
        cmd += f" -query {self.input_fasta}"
        cmd += f" -word_size {word_size}"
        cmd += " -outfmt 11"
        cmd += f" -out {output_archive}"

        # Run
        subprocess.run(cmd, check=True, shell=True)

        # Save as instance variable, for reformattings
        self.output_archive = output_archive

        return self

    def reformat_output_as_table(self, output_table):
        """
        Reformat the output from `self.run()` to a table form,
        e.g. `-outfmt 6`.

        """

        # Define command
        cmd = "blast_formatter"
        cmd += f" -archive {self.output_archive}"
        cmd += f" -outfmt '6 {self.BLAST_COLS}'"
        cmd += f" -out {output_table}"

        # Run
        subprocess.run(cmd, check=True, shell=True)

        # Save
        self.output_table = output_table

        return self

    def _load_as_dataframe(self):
        """
        Load tabular BLAST output as a pandas dataframe

        TODO:
        - Could optionally allow for column name remapping here,
        and basic munging

        """

        # Load as a dataframe
        self.blast_df = pd.read_csv(
            self.output_table, sep="\t", names=self.BLAST_COLS.split(" ")
        )

    def get_dataframe(self):
        """
        Return a dataframe of tabular BLAST results

        """

        self._load_as_dataframe()

        return self.blast_df

    @staticmethod
    def biopython_process_blast_results(blast_xml: str):
        """
        Import BLAST records from a BLAST search xml file.

        Args:
            blast_xml: An xml file generated by running the BLAST CLI tool

        Returns:
            A blast record object. For a description of the BLAST object class, see here:
            https://biopython.org/docs/dev/Tutorial/chapter_blast.html#the-blast-records-record-and-hit-classes
        """
        out = []

        with Blast.parse(blast_xml) as blast_records:
            for blast_record in blast_records:
                print(blast_record)

        return out


def run_blast_pipeline(primer_csv, genome_fasta, output_dir=None, params=None):
    """
    BLAST primers in `primer_csv` against reference genome given by `genome_fasta` to
    find off-target binding sites and amplicons.

    Args:
        primer_csv (str): Path to CSV containing primers. Must have 'primer_name' and 'seq' columns.
        genome_fasta (str): Path to reference genome FASTA.
        output_dir (str): Directory for output. If None, uses 'blast' subdir of input CSV.
        params (dict): Optional BLAST parameters (word_size, evalue_threshold, etc.)
    """

    # Defaults
    if params is None:
        params = {
            "word_size": 7,
            "alignment_length_threshold": 12,
            "evalue_threshold": 4,
        }

    input_dir = os.path.dirname(primer_csv)
    if output_dir is None:
        output_dir = os.path.join(input_dir, "blast")

    os.makedirs(output_dir, exist_ok=True)

    print("Running BLAST pipeline...")
    print(f"  Primer CSV: {primer_csv}")
    print(f"  Genome: {genome_fasta}")
    print(f"  Output: {output_dir}")

    # LOAD DATA
    primer_df = pd.read_csv(primer_csv)
    print(f"  Found {primer_df.shape[0]} primers.")

    # WRITE PRIMER FASTA
    primer_dt = dict(zip(primer_df["primer_name"], primer_df["seq"], strict=False))
    primer_fasta = f"{output_dir}/candidate_primer.fasta"
    write_fasta_from_dict(input_dt=primer_dt, output_fasta=primer_fasta)

    # RUN BLAST
    blast_df = (
        BlastRunner(input_fasta=primer_fasta, reference_fasta=genome_fasta)
        .create_database()
        .run(
            word_size=params.get("word_size", 7),
            output_archive=f"{output_dir}/blast.candidate_primers.archive",
        )
        .reformat_output_as_table(
            output_table=f"{output_dir}/blast.candidate_primers.table"
        )
        .get_dataframe()
    )

    # ANNOTATE RESULTS
    annotator = BlastResultsAnnotator(blast_df)
    annotator.build_annotation_dict(
        length_threshold=params.get("alignment_length_threshold", 12),
        evalue_threshold=params.get("evalue_threshold", 4),
    )
    annotator.add_annotations()
    annotator.summarise_by_primer(
        f"{output_dir}/table.blast.candidate_primers.summary.csv"
    )
    print(f"  Found {blast_df.shape[0]} BLAST hits.")

    # PREDICT AMPLICONS
    bound_df = annotator.get_predicted_bound()
    print(f"  Found {bound_df.shape[0]} putative primer binding sites.")

    amplicon_finder = AmpliconFinder(bound_df)
    amplicon_finder.find_amplicons()

    amplicon_df = amplicon_finder.amplicon_df
    if amplicon_df is not None:
        print(f"  Yielding {amplicon_df.shape[0]} potential amplicons.")
        amplicon_df.to_csv(f"{output_dir}/table.predicted_amplicons.csv")

        amplicon_finder.create_ontarget_dataframe(primer_df)
        amplicon_finder.create_offtarget_dataframe()

        if amplicon_finder.ontarget_df is not None:
            amplicon_finder.ontarget_df.to_csv(
                f"{output_dir}/table.ontarget_amplicons.csv"
            )
        if amplicon_finder.offtarget_df is not None:
            amplicon_finder.offtarget_df.to_csv(
                f"{output_dir}/table.offtarget_amplicons.csv"
            )
    else:
        print("  No amplicons found.")

    print("BLAST pipeline complete.")
